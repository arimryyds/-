# 线性回归
- 回归处理的问题为预测：
    - 预测房价
    - 销售额的预测
    - 设定贷款额度
    - 总结：上述案例中，可以根据事物的相关特征预测出对应的结果值

## 什么是回归
那么，这个回归究竟是什么意思呢？其实**回归算法**是相对**分类算法**而言的，与我们想要预测的目标变量y的值类型有关。如果目标变量y是分类型变量，如预测用户的性别（男、女），预测月季花的颜色（红、白、黄……），预测是否患有肺癌（是、否），那我们就需要用分类算法去拟合训练数据并做出预测；

如果y是连续型变量，如预测用户的收入（4千，2万，10万……），预测员工的通勤距离（500m，1km，2万里……），预测患肺癌的概率（1%，50%，99%……），我们则需要用回归模型。

## 一元线性回归
线性回归可以说是用法非常简单、，作为机器学习的入门算法非常合适。我们上中学的时候，都学过二元一次方程，我们将y作为因变量，x作为自变量，得到方程：


![Image Name](https://cdn.kesci.com/upload/image/rdpp0iov9p.png)



当给定参数β0和β1的时候，画在坐标图内是**一条直线（这就是“线性”的含义**）。

当我们只用一个x来预测y，**就是一元线性回归**，也就是在找一个直线来拟合数据。

比如，我有一组数据画出来的散点图，横坐标代表广告投入金额，纵坐标代表销售量，**线性回归就是要找一条直线，并且让这条直线尽可能地拟合图中的数据点。**


![Image Name](https://cdn.kesci.com/upload/image/rdpp92i7n.png?imageView2/0/w/960/h/960)




这里我们得到的拟合方程是y = 0.0512x + 7.1884，此时当我们获得一个新的广告投入金额后，我们就可以用这个方程预测出大概的销售量。

线性回归（Linear Regression）是一种用于建立和分析关于两个或多个变量之间线性关系的统计方法和机器学习算法。它被广泛应用于预测和建模任务，尤其是用于预测数值型输出（连续型变量）。

线性回归的基本思想是寻找自变量（输入特征）与因变量（输出目标）之间的线性关系，即一个线性方程，用来描述这些变量之间的关系。一般来说，线性回归模型的方程如下：
![image.png](image.png)

线性回归适用于以下情况：

- 希望理解和建模两个或多个变量之间的线性关系。  
- 需要进行数值型输出的预测。   
- 需要估计特征对目标变量的影响。  
- 需要进行简单的模型解释和解释能力较强的建模。  

线性回归是机器学习和统计学中最简单但也是最有用的工具之一，它为许多预测问题提供了一个坚实的基础。在实际应用中，线性回归通常有多种变体，如多元线性回归、岭回归、Lasso回归等，以适应不同问题的需求。

注意 :做线性回归，不要忘了前提假设是y和x呈线性关系，如果两者不是线性关系，就要选用其他的模型啦。




## 线性回归案例


```python
#导入必要的库
import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# 加载波士顿房价数据集
boston = datasets.load_boston()
```


```python
#data：这是一个NumPy数组，包含了数据集的特征值。每一行代表一个数据样本，每一列代表一个特征。
boston.data
```




    array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,
            4.9800e+00],
           [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,
            9.1400e+00],
           [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,
            4.0300e+00],
           ...,
           [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,
            5.6400e+00],
           [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,
            6.4800e+00],
           [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,
            7.8800e+00]])




```python
#feature_names：这是一个字符串数组，包含了与data中的列对应的特征名称。
boston.feature_names
```




    array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',
           'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')




```python
#target：这是一个NumPy数组，包含了数据集的目标变量，也就是房价。
boston.target
```




    array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,
           18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,
           15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,
           13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,
           21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,
           35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,
           19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,
           20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,
           23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,
           33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,
           21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,
           20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,
           23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,
           15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,
           17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,
           25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,
           23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,
           32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,
           34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,
           20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,
           26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,
           31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,
           22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,
           42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,
           36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,
           32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,
           20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,
           20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,
           22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,
           21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,
           19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,
           32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,
           18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,
           16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,
           13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,
            7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,
           12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,
           27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,
            8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,
            9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,
           10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,
           15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,
           19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,
           29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,
           20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,
           23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])




```python
# 转换数据为DataFrame
boston_df = pd.DataFrame(boston.data, columns=boston.feature_names)
```


```python
boston_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
    </tr>
  </tbody>
</table>
</div>



CRIM：各城镇的人均犯罪率。

ZN：占地面积超过 25,000 平方英尺的住宅用地的比例。

INDUS：城镇非零售商业用地的比例。

CHAS：查尔斯河虚拟变量（如果一条街道临近查尔斯河，取值为1；否则，取值为0）。

NOX：一氧化氮浓度（每百万份）。

RM：住宅平均房间数。

AGE：1940 年之前建造的自住房屋的比例。

DIS：到就业中心的加权距离。

RAD：到径向公路的可达性指数。

TAX：房产税率。

PTRATIO：城镇的师生比例。

B：1000(Bk - 0.63)^2，其中Bk是城镇中黑人的比例。

LSTAT：较低社会地位人口的百分比。

MEDV：自住房的中位数房价，这是该数据集的目标变量。


```python
boston_df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 506 entries, 0 to 505
    Data columns (total 13 columns):
    CRIM       506 non-null float64
    ZN         506 non-null float64
    INDUS      506 non-null float64
    CHAS       506 non-null float64
    NOX        506 non-null float64
    RM         506 non-null float64
    AGE        506 non-null float64
    DIS        506 non-null float64
    RAD        506 non-null float64
    TAX        506 non-null float64
    PTRATIO    506 non-null float64
    B          506 non-null float64
    LSTAT      506 non-null float64
    dtypes: float64(13)
    memory usage: 51.5 KB



```python
# 将目标（房价）添加到DataFrame
boston_df['PRICE'] = boston.target
```


```python
boston.target
```




    array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,
           18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,
           15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,
           13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,
           21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,
           35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,
           19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,
           20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,
           23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,
           33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,
           21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,
           20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,
           23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,
           15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,
           17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,
           25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,
           23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,
           32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,
           34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,
           20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,
           26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,
           31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,
           22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,
           42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,
           36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,
           32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,
           20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,
           20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,
           22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,
           21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,
           19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,
           32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,
           18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,
           16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,
           13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,
            7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,
           12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,
           27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,
            8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,
            9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,
           10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,
           15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,
           19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,
           29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,
           20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,
           23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])




```python
# 划分特征和目标变量
X = boston_df.drop('PRICE', axis=1)
y = boston_df['PRICE']
```


```python
# 划分数据集为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)
```


```python
X_train
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>379</td>
      <td>17.86670</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.6710</td>
      <td>6.223</td>
      <td>100.0</td>
      <td>1.3861</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>393.74</td>
      <td>21.78</td>
    </tr>
    <tr>
      <td>311</td>
      <td>0.79041</td>
      <td>0.0</td>
      <td>9.90</td>
      <td>0.0</td>
      <td>0.5440</td>
      <td>6.122</td>
      <td>52.8</td>
      <td>2.6403</td>
      <td>4.0</td>
      <td>304.0</td>
      <td>18.4</td>
      <td>396.90</td>
      <td>5.98</td>
    </tr>
    <tr>
      <td>157</td>
      <td>1.22358</td>
      <td>0.0</td>
      <td>19.58</td>
      <td>0.0</td>
      <td>0.6050</td>
      <td>6.943</td>
      <td>97.4</td>
      <td>1.8773</td>
      <td>5.0</td>
      <td>403.0</td>
      <td>14.7</td>
      <td>363.43</td>
      <td>4.59</td>
    </tr>
    <tr>
      <td>244</td>
      <td>0.20608</td>
      <td>22.0</td>
      <td>5.86</td>
      <td>0.0</td>
      <td>0.4310</td>
      <td>5.593</td>
      <td>76.5</td>
      <td>7.9549</td>
      <td>7.0</td>
      <td>330.0</td>
      <td>19.1</td>
      <td>372.49</td>
      <td>12.50</td>
    </tr>
    <tr>
      <td>56</td>
      <td>0.02055</td>
      <td>85.0</td>
      <td>0.74</td>
      <td>0.0</td>
      <td>0.4100</td>
      <td>6.383</td>
      <td>35.7</td>
      <td>9.1876</td>
      <td>2.0</td>
      <td>313.0</td>
      <td>17.3</td>
      <td>396.90</td>
      <td>5.77</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>343</td>
      <td>0.02543</td>
      <td>55.0</td>
      <td>3.78</td>
      <td>0.0</td>
      <td>0.4840</td>
      <td>6.696</td>
      <td>56.4</td>
      <td>5.7321</td>
      <td>5.0</td>
      <td>370.0</td>
      <td>17.6</td>
      <td>396.90</td>
      <td>7.18</td>
    </tr>
    <tr>
      <td>359</td>
      <td>4.26131</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.7700</td>
      <td>6.112</td>
      <td>81.3</td>
      <td>2.5091</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>390.74</td>
      <td>12.67</td>
    </tr>
    <tr>
      <td>323</td>
      <td>0.28392</td>
      <td>0.0</td>
      <td>7.38</td>
      <td>0.0</td>
      <td>0.4930</td>
      <td>5.708</td>
      <td>74.3</td>
      <td>4.7211</td>
      <td>5.0</td>
      <td>287.0</td>
      <td>19.6</td>
      <td>391.13</td>
      <td>11.74</td>
    </tr>
    <tr>
      <td>280</td>
      <td>0.03578</td>
      <td>20.0</td>
      <td>3.33</td>
      <td>0.0</td>
      <td>0.4429</td>
      <td>7.820</td>
      <td>64.5</td>
      <td>4.6947</td>
      <td>5.0</td>
      <td>216.0</td>
      <td>14.9</td>
      <td>387.31</td>
      <td>3.76</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0.21124</td>
      <td>12.5</td>
      <td>7.87</td>
      <td>0.0</td>
      <td>0.5240</td>
      <td>5.631</td>
      <td>100.0</td>
      <td>6.0821</td>
      <td>5.0</td>
      <td>311.0</td>
      <td>15.2</td>
      <td>386.63</td>
      <td>29.93</td>
    </tr>
  </tbody>
</table>
<p>404 rows × 13 columns</p>
</div>




```python
X_test
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>198</td>
      <td>0.03768</td>
      <td>80.0</td>
      <td>1.52</td>
      <td>0.0</td>
      <td>0.404</td>
      <td>7.274</td>
      <td>38.3</td>
      <td>7.3090</td>
      <td>2.0</td>
      <td>329.0</td>
      <td>12.6</td>
      <td>392.20</td>
      <td>6.62</td>
    </tr>
    <tr>
      <td>229</td>
      <td>0.44178</td>
      <td>0.0</td>
      <td>6.20</td>
      <td>0.0</td>
      <td>0.504</td>
      <td>6.552</td>
      <td>21.4</td>
      <td>3.3751</td>
      <td>8.0</td>
      <td>307.0</td>
      <td>17.4</td>
      <td>380.34</td>
      <td>3.76</td>
    </tr>
    <tr>
      <td>502</td>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
    </tr>
    <tr>
      <td>31</td>
      <td>1.35472</td>
      <td>0.0</td>
      <td>8.14</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.072</td>
      <td>100.0</td>
      <td>4.1750</td>
      <td>4.0</td>
      <td>307.0</td>
      <td>21.0</td>
      <td>376.73</td>
      <td>13.04</td>
    </tr>
    <tr>
      <td>315</td>
      <td>0.25356</td>
      <td>0.0</td>
      <td>9.90</td>
      <td>0.0</td>
      <td>0.544</td>
      <td>5.705</td>
      <td>77.7</td>
      <td>3.9450</td>
      <td>4.0</td>
      <td>304.0</td>
      <td>18.4</td>
      <td>396.42</td>
      <td>11.50</td>
    </tr>
    <tr>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <td>166</td>
      <td>2.01019</td>
      <td>0.0</td>
      <td>19.58</td>
      <td>0.0</td>
      <td>0.605</td>
      <td>7.929</td>
      <td>96.2</td>
      <td>2.0459</td>
      <td>5.0</td>
      <td>403.0</td>
      <td>14.7</td>
      <td>369.30</td>
      <td>3.70</td>
    </tr>
    <tr>
      <td>401</td>
      <td>14.23620</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.693</td>
      <td>6.343</td>
      <td>100.0</td>
      <td>1.5741</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>396.90</td>
      <td>20.32</td>
    </tr>
    <tr>
      <td>368</td>
      <td>4.89822</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.631</td>
      <td>4.970</td>
      <td>100.0</td>
      <td>1.3325</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>375.52</td>
      <td>3.26</td>
    </tr>
    <tr>
      <td>140</td>
      <td>0.29090</td>
      <td>0.0</td>
      <td>21.89</td>
      <td>0.0</td>
      <td>0.624</td>
      <td>6.174</td>
      <td>93.6</td>
      <td>1.6119</td>
      <td>4.0</td>
      <td>437.0</td>
      <td>21.2</td>
      <td>388.08</td>
      <td>24.16</td>
    </tr>
    <tr>
      <td>428</td>
      <td>7.36711</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.679</td>
      <td>6.193</td>
      <td>78.1</td>
      <td>1.9356</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>96.73</td>
      <td>21.52</td>
    </tr>
  </tbody>
</table>
<p>102 rows × 13 columns</p>
</div>




```python
y_train
```




    379    10.2
    311    22.1
    157    41.3
    244    17.6
    56     24.7
           ... 
    343    23.9
    359    22.6
    323    18.5
    280    45.4
    8      16.5
    Name: PRICE, Length: 404, dtype: float64




```python
y_test
```




    198    34.6
    229    31.5
    502    20.6
    31     14.5
    315    16.2
           ... 
    166    50.0
    401     7.2
    368    50.0
    140    14.0
    428    11.0
    Name: PRICE, Length: 102, dtype: float64




```python
# 创建线性回归模型
model = LinearRegression()

# 拟合模型
model.fit(X_train, y_train)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)




```python
# 预测房价
y_pred = model.predict(X_test)
y_pred
```




    array([34.4081095 , 31.18524626, 22.31286141, 17.88613877, 20.43572131,
           26.14444413, 26.21920244, 23.57978445, 22.41577853, 19.51182817,
           26.86691495, 17.20411302, 20.68511041, 15.67921778, 41.69912781,
           20.2946735 , 28.99258631, 19.06413492, 32.48035595, 41.13627224,
           34.64732462, 16.38997909, 20.42215729, 18.05324255, 13.38743087,
           12.64800748, 27.45930237, 20.30199107, 18.78954741, 20.24950994,
           15.60161419, 24.38040555, 38.95651978, 24.7184131 , 31.26791961,
           28.26279775, 15.84707127, 14.76661568, 16.79024244, 23.23674899,
           22.85417065, 23.48976177, 14.16818173, 21.42613087, 32.38362329,
           26.7881669 , 19.37574824, 15.27894103, 17.21175121, 12.91591919,
           21.84063224, 20.25050371, 23.65622638, 23.9608324 , 11.94749102,
           14.49718052, 24.69872363, 34.18169066, 10.30437821, 21.04686616,
           17.96204214, 19.76593459, 17.45231513, 29.982971  , 20.73183476,
           25.24657823, 15.81416285, 24.96705225, 22.1298931 , 20.77593563,
           18.69600904, 24.2201495 ,  4.37889874, 15.95687399, 28.03130587,
            9.28438308, 24.76810967, 35.14238234, 11.61172029, 27.04175401,
           34.84290485, 40.44603313, 13.93219791, 15.95544402, 19.26007763,
           12.76037799, 20.90536105, 23.85659356, 13.17899179, 14.76828889,
           32.31355353, 22.93635318, 24.63095357, 23.51981407, 19.34136578,
           22.83582245, 21.72263765, 36.18508621, 18.01097012, 23.18226475,
           13.77270991, 14.43864146])




```python
# 创建一个新的DataFrame，将实际值、预测值和特征合并在一起
results_df = X_test.copy()
results_df['Actual_Price'] = y_test
results_df['Predicted_Price'] = y_pred
```


```python
results_df.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>Actual_Price</th>
      <th>Predicted_Price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>198</td>
      <td>0.03768</td>
      <td>80.0</td>
      <td>1.52</td>
      <td>0.0</td>
      <td>0.404</td>
      <td>7.274</td>
      <td>38.3</td>
      <td>7.3090</td>
      <td>2.0</td>
      <td>329.0</td>
      <td>12.6</td>
      <td>392.20</td>
      <td>6.62</td>
      <td>34.6</td>
      <td>34.408110</td>
    </tr>
    <tr>
      <td>229</td>
      <td>0.44178</td>
      <td>0.0</td>
      <td>6.20</td>
      <td>0.0</td>
      <td>0.504</td>
      <td>6.552</td>
      <td>21.4</td>
      <td>3.3751</td>
      <td>8.0</td>
      <td>307.0</td>
      <td>17.4</td>
      <td>380.34</td>
      <td>3.76</td>
      <td>31.5</td>
      <td>31.185246</td>
    </tr>
    <tr>
      <td>502</td>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
      <td>22.312861</td>
    </tr>
    <tr>
      <td>31</td>
      <td>1.35472</td>
      <td>0.0</td>
      <td>8.14</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.072</td>
      <td>100.0</td>
      <td>4.1750</td>
      <td>4.0</td>
      <td>307.0</td>
      <td>21.0</td>
      <td>376.73</td>
      <td>13.04</td>
      <td>14.5</td>
      <td>17.886139</td>
    </tr>
    <tr>
      <td>315</td>
      <td>0.25356</td>
      <td>0.0</td>
      <td>9.90</td>
      <td>0.0</td>
      <td>0.544</td>
      <td>5.705</td>
      <td>77.7</td>
      <td>3.9450</td>
      <td>4.0</td>
      <td>304.0</td>
      <td>18.4</td>
      <td>396.42</td>
      <td>11.50</td>
      <td>16.2</td>
      <td>20.435721</td>
    </tr>
    <tr>
      <td>169</td>
      <td>2.44953</td>
      <td>0.0</td>
      <td>19.58</td>
      <td>0.0</td>
      <td>0.605</td>
      <td>6.402</td>
      <td>95.2</td>
      <td>2.2625</td>
      <td>5.0</td>
      <td>403.0</td>
      <td>14.7</td>
      <td>330.04</td>
      <td>11.32</td>
      <td>22.3</td>
      <td>26.144444</td>
    </tr>
    <tr>
      <td>111</td>
      <td>0.10084</td>
      <td>0.0</td>
      <td>10.01</td>
      <td>0.0</td>
      <td>0.547</td>
      <td>6.715</td>
      <td>81.6</td>
      <td>2.6775</td>
      <td>6.0</td>
      <td>432.0</td>
      <td>17.8</td>
      <td>395.59</td>
      <td>10.16</td>
      <td>22.8</td>
      <td>26.219202</td>
    </tr>
    <tr>
      <td>206</td>
      <td>0.22969</td>
      <td>0.0</td>
      <td>10.59</td>
      <td>0.0</td>
      <td>0.489</td>
      <td>6.326</td>
      <td>52.5</td>
      <td>4.3549</td>
      <td>4.0</td>
      <td>277.0</td>
      <td>18.6</td>
      <td>394.87</td>
      <td>10.97</td>
      <td>24.4</td>
      <td>23.579784</td>
    </tr>
    <tr>
      <td>108</td>
      <td>0.12802</td>
      <td>0.0</td>
      <td>8.56</td>
      <td>0.0</td>
      <td>0.520</td>
      <td>6.474</td>
      <td>97.1</td>
      <td>2.4329</td>
      <td>5.0</td>
      <td>384.0</td>
      <td>20.9</td>
      <td>395.24</td>
      <td>12.27</td>
      <td>19.8</td>
      <td>22.415779</td>
    </tr>
    <tr>
      <td>420</td>
      <td>11.08740</td>
      <td>0.0</td>
      <td>18.10</td>
      <td>0.0</td>
      <td>0.718</td>
      <td>6.411</td>
      <td>100.0</td>
      <td>1.8589</td>
      <td>24.0</td>
      <td>666.0</td>
      <td>20.2</td>
      <td>318.75</td>
      <td>15.02</td>
      <td>16.7</td>
      <td>19.511828</td>
    </tr>
  </tbody>
</table>
</div>




```python
# 计算均方误差
mse = mean_squared_error(y_test, y_pred)
mse
```




    23.616994100563634




```python
# 计算R-squared（决定系数）
r2 = r2_score(y_test, y_pred)
r2
```




    0.7555033086871304



## 线性回归的评价指标

>1. **均方误差（Mean Squared Error，MSE）**：MSE是最常用的线性回归模型评价指标之一。它计算了模型的预测值与实际观测值之间的平方差的平均值。MSE越小，模型的拟合能力越好。  
公式：MSE = Σ(yi - ŷi)² / n，其中 yi 表示实际观测值，ŷi 表示模型的预测值，n 表示样本数量。  

>2. **均方根误差（Root Mean Squared Error，RMSE）**：RMSE是MSE的平方根，它在与实际数据单位相同的度量下提供了误差的平均大小。RMSE也越小越好。   
公式：RMSE = √(Σ(yi - ŷi)² / n)  

>3. **平均绝对误差（Mean Absolute Error，MAE）**：MAE计算了模型的预测值与实际观测值之间的绝对差的平均值。MAE越小，表示模型对数据的拟合越好。  
公式：MAE = Σ|yi - ŷi| / n  

>4. **决定系数（Coefficient of Determination，R-squared，R²）**：R²度量了线性回归模型对数据的拟合程度。它的取值范围在0到1之间，越接近1表示模型拟合得越好。  
公式：R² = 1 - (Σ(yi - ŷi)² / Σ(yi - ȳ)²)，其中 yi 表示实际观测值，ŷi 表示模型的预测值，ȳ 表示实际观测值的均值。


```python

```
